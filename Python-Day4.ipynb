{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDpc1awHybfm"
   },
   "source": [
    "## What is python and why do we need it/why are you taking this workshop?\n",
    "\n",
    "* Python is a programming language that is commonly used for data analysis\n",
    "* R is another commonly used programming language, probably second to python\n",
    "* Python is more general purpose than R, which is specifically for data analysis\n",
    "* Programming languages are a way for humans to give the computer commands\n",
    "* Regardless of how you collect data, it needs to be analyzed and code is the best way (Don't use excel!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APR4I085x85H"
   },
   "source": [
    "## Jupyter basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaMuZb0Ux85I"
   },
   "source": [
    "Jupyter notebooks are text files that can be rendered as formatted text **and** run code given the proper setup (see Installation).\n",
    "\n",
    "Text is split into **cells**. Double clicking a cell allows you to edit it.\n",
    "\n",
    "For code cells, there is also an option to run the code. You can do this by pressing **SHIFT+ENTER** while having it selected, or press the **Run** button at the top of the cell (exact location depends on the editor you're using). Because of the way we set up the notebook the code cells will be running Python code.\n",
    "\n",
    "For this workshop, we'll be asking you to follow along by running code cells and by doing coding exercises by writing or editing code in code cell.\n",
    "\n",
    "**IMPORTANT**: Run the code cells below to **import** the **libraries** we'll be using during this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeWBR6Qzx85J"
   },
   "outputs": [],
   "source": [
    "# Run this cell to import the libraries we'll be using\n",
    "# If you don't have the kernel loaded or installed, it will not work\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNBH_ghJy1-t"
   },
   "source": [
    "And run the following to demonstrate how the code blocks run and display code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJXQSXqex85K",
    "outputId": "af2efcc0-3850-49a8-c462-79c0f3c0d560"
   },
   "outputs": [],
   "source": [
    "# Run this cell to print a message to the screen\n",
    "print(\"this is my code cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFmyJigzx85L"
   },
   "source": [
    "Any **variables** that you assign in one cell will be available in other cells. But they will not be saved between sessions. If you close the notebook and re-open it, you will need to re-run the previous cells to get your variables back. Therefore, it's important to be aware of the state of your notebook and the order in which your cells were run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vhlutrYx85M"
   },
   "outputs": [],
   "source": [
    "my_string = \"this is my code cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QihRWpxx85M",
    "outputId": "720aad52-c36b-44f5-d20a-1727b6757423"
   },
   "outputs": [],
   "source": [
    "print(my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSfN6lPvx85N"
   },
   "source": [
    "Jupyter notebooks can be exported to pdf or html, so that other people can view both the code and its output. It's a good format for handing in homeworks, for example, since you can show your work. In this notebook, there will be exercises with placeholders for the code that you will have to fill in. For these exercises, we encourage you to work with each other, use google, LLMs, and whatever other resources if you are stuck. It's not an exam, but just a way to get practice of the concepts. Afterwards, we will post the completed notebook on our website so you can have examples of solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWA8FQAFx85O"
   },
   "source": [
    "## Python refresher\n",
    "\n",
    "Let's begin by reviewing some of the terms we've covered in the past sessions that will come up again today.\n",
    "\n",
    "| Term | Definition |\n",
    "| --- | --- |\n",
    "| Object | The thing itself (an instance of a class) |\n",
    "| Variable | The name we give the object (a pointer to the object) |\n",
    "| Class | The blueprint for the object (defines the attributes and methods of object) |\n",
    "| Method | A function that belongs to an object |\n",
    "| Attribute | A property of an object |\n",
    "| Function | A piece of code that takes an input and gives an output/does something |\n",
    "| Argument| The objects that are passed to the function for it to operate on |\n",
    "| Library | Collections of python functions/capabilities that can be installed and loaded on top of base python\n",
    "\n",
    "### Object Methods\n",
    "\n",
    "Everything in python is an **object**, and depending on the type of object, they may have certain **methods** that can be called on them. For example, strings have a method called `upper()` that converts the string to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3vIR3pGx85O",
    "outputId": "db951619-38bb-4abc-dada-a788e710a0fd"
   },
   "outputs": [],
   "source": [
    "my_string = \"hello\"\n",
    "my_string.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsM7-4-1x85P"
   },
   "source": [
    "\n",
    "In the above code, `my_string` is a string object, and we are calling the `upper()` method on it. The method is called by using the `.` operator. Methods are functions that can only be used on objects of certain classes. You will often see methods strung together, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYHSD4Wfx85P",
    "outputId": "ff8afc93-7676-4b18-f7da-dd5064e83dbd"
   },
   "outputs": [],
   "source": [
    "my_string = \"hello\"\n",
    "# This first makes the first letter uppercase, then swaps the cases of each letter\n",
    "my_string.capitalize().swapcase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMVxjr-8x85Q"
   },
   "source": [
    "### Object Attributes\n",
    "\n",
    "We'll be learning about some more complex objects today, like **numpy arrays**, which also have attributes. **Attributes** are properties of an object that can be accessed using the `.` operator. For example, numpy arrays have an attribute called `shape` that tells you the dimensions of the array. The difference between an attribute and a method is that attributes are information about a given object, rather than a task being performed on the object. Practically, this means that, while both attributes and methods are called on an object with the dot operator `.`, attributes are accessed without parentheses, so you don't need to call them like functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0R3_Dcfx85Q",
    "outputId": "79026dbf-3fc0-4833-fe64-3949d9476c5e"
   },
   "outputs": [],
   "source": [
    "# this makes a np array (we'll learn more about these shortly!)\n",
    "my_array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# this gets the size (total number of elements) of the array\n",
    "my_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLrox8L_x85R"
   },
   "source": [
    "## Base Python Data Structures\n",
    "\n",
    "When we want to store multiple pieces of data, we use data structures, which are a more complex type of object. We will go over two fundamental data structures that exist in base python (i.e. that don't require additional libraries). \n",
    "\n",
    "### Lists\n",
    "\n",
    "**Lists** are one the most flexible of data structures in Python. They are created with `[]` and can contain any type of data. Each **element** in a list is separated by a comma. Lists are ordered and can be indexed, sliced, and concatenated just like strings. When lists are all numerical, they can also support mathematical operations like `max()` and `min()`. Lists can also be nested using another `[]` within the list.\n",
    "\n",
    "Lists are our first introduction to a **mutable** data structure, meaning you can change a list without having to create a new one. Indeed, list methods may modify your data **in place** and/or **return** a new object. If the method modifies the object in place, its return value will be `None`. Modifying in place means you don't have to assign the result of the method to a new variable, while returning a new object means you do have to assign it. For example, `list.append(x)` updates the list in place, while `list.pop()` both returns the last element and removes it from the list in place.\n",
    "\n",
    "Below are some useful operations and methods for lists. For a full list of methods, you can use `help()` on the list or consult the [docs](https://docs.python.org/3/library/stdtypes.html#list) page.\n",
    "\n",
    "**Operations and methods for lists**\n",
    "\n",
    "| Operation/Method | Description |\n",
    "| --- | --- |\n",
    "| `+` | Concatenation |\n",
    "| `*` | Repetition |\n",
    "| `[]`, `[:]` | Indexing, slicing |\n",
    "| `.append(x)` | Add `x` to the end of the list |\n",
    "| `.extend([x, y, z])` | Add `[x, y, z]` to the end of the list |\n",
    "| `.insert(i, x)` | Add `x` at index `i` of the list |\n",
    "| `.pop(i)` | Remove and return the element at index `i`, defaults to last element if none given |\n",
    "\n",
    "**Use cases for lists**\n",
    "\n",
    "Lists are a data structure that is always there in the background, being useful. We see them when creating simple ordered collections to iterate through, when we need to store a sequence of data to reference later, or when we need to collected a bunch of objects together. Think of lists as a small temporary transport for data. Lists are not good for large datasets (because it will be slow) or when you need to do a lot of mathematical operations (because it lacks functionality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "**Dictionaries** store **key:value pairs**. Keys must be immutable and are typically strings or numerical identifiers, while the values can be just about anything, including other dictionaries, lists, or individual values. You can create a dictionary with `{}` or with the `dict()` function. The two ways to create a dictionary are shown below:\n",
    "\n",
    "```python\n",
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "my_dict = dict((\"a\", 1), (\"b\", 2), (\"c\", 3))\n",
    "```\n",
    "\n",
    "In recent versions of Python (3.8+), dictionaries keys maintain the order in which they were added, which is useful to maintain consistency when looping over the keys. However, in previous versions of Python, dictionaries were unordered. You can't index or slice dictionaries (since dictionary elements aren't accessed by index). But you can retrieve items by their key, e.g. `my_dict[\"a\"]` or `my_dict.get(\"a\")`. Like lists, dictionaries are mutable, so you can add, remove, or update the key:value pairs in place. Other methods return \"View objects\" that allow you to see the items in the dictionary, but won't allow you to modify the dictionary, however these objects can usually be easily converted to lists with the `list()` function. Here are some useful methods for dictionaries:\n",
    "\n",
    "**Operations and methods for dictionaries**\n",
    "\n",
    "| Operation/Method | Description |\n",
    "| --- | --- |\n",
    "| `[<key>]` | Retrieve value by key |\n",
    "| `.keys()` | Returns a view object of the keys |\n",
    "| `.values()` | Returns a view object of the values |\n",
    "| `.items()` | Returns a view object of the key:value pairs |\n",
    "| `.update(dict)` | Updates the dictionary with the key:value pairs from another dictionary |\n",
    "\n",
    "**Use cases for dictionaries**\n",
    "\n",
    "Dictionaries are a data structure that is more specialized for information that can be organized in a key:value pair way. You may see dictionaries being used to store associations between a name/ID and some characteristics, or to store a set of parameters for a function, or to organize a hierarchical grouping of information. Dictionaries are optimized for fast access to the values by key and for flexible organization of the data. Although you can edit the values of a dictionary, they aren't good for mathematical operations or for ordered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdBpVzLxx85S"
   },
   "source": [
    "## Learning to read documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T9EBiwqx85S"
   },
   "source": [
    "Today our first lesson will be about how to read documentation, because we are going to start using libraries such as **numpy** and **pandas**, which have many features that we do not have the time to cover in detail. Instead, if you can read documentation efficiently, you can learn how to use these libraries on your own.\n",
    "\n",
    "\n",
    "**Programming effectively actually involves a lot of reading**\n",
    "\n",
    "Programming involves reading primarily documentation, but also code, search results, stackexchange queries, etc. These are just a few examples of what you'll read as you work on code. Reading the documentation of a package or library or software that you are using should probably be the first thing you do when you start using it. However, software docs pages are a much different sort of writing than we may be used to, if we're primarily used to reading journal articles, textbooks, and protocols. Knowing how and how much to read documentation is a skill that needs to be developed over time to suit your own needs. There's definitely no need to read every single page of documentation of a piece of software, especially for large libraries like `numpy` or `matplotlib`.\n",
    "\n",
    "**There are a variety of ways software can be documented**\n",
    "\n",
    "You may be handed a single script from a colleague to perform some action and that script may have **comments** in the code detailing what it does or what certain lines do. Individual functions may have what is called a **docstring**, which is a string that occurs immediately after the function definition detailing how do use that function, inputs, and outputs. Another type of documentation is a docs page or **API reference** on a website for that software, such as the page for the seaborn's [scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) function. Many software packages also have some introductory pages like **vignettes** or **tutorials** that guide you through the basics of the software. The [Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html) of Pandas is a good example of this.\n",
    "\n",
    "**What documentation are we meant to read?**\n",
    "\n",
    "In general, documentation is meant to be a reference manual more than a textbook. A lot of documentation is really repetitive, because it has to exhaustively cover every single function, class, and use-case available to the user. I do not recommend reading documentation like a book or in any linear way. That's like learning a foreign language by reading the dictionary. For example, `numpy` has a variety of [mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html), but you are not required to look at the doc page of each of those. It is enough to know that it exists and when you do want to use a particular one, to check the page of that specific function. The most important parts of the documentation to read first are the tutorials/user guides, which introduce the basic functionality of the software with some example code. Often times, this code is exactly what you need to get started. If you get stuck, then it's time to read the docs pages for the specific commands you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASCXtv_6x85S"
   },
   "source": [
    "### Anatomy of a docs page\n",
    "\n",
    "Scientific articles typically have the same sections: Introduction, Methods, Results/Discussion. Similarly, docs pages for a function should all have some common components:\n",
    "\n",
    "* Function name and how to call it\n",
    "    * parameters in parentheses with any defaults showing\n",
    "    * positional parameters first, keyword parameters after asterisk\n",
    "* Description of function\n",
    "* Detailed parameters that can be passed to each function\n",
    "    * type of object that can be passed\n",
    "    * description of what the parameter does\n",
    "* Returns\n",
    "    * type of object(s) returned\n",
    "    * description of the object\n",
    "* Examples\n",
    "\n",
    "**Just the basics**\n",
    "\n",
    "If this is your first time encountering the function, glance at the function name and description and then go directly to the examples. This will help you understand if this function does what you think it does and give you a template to use it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKr51JVhx85S"
   },
   "source": [
    ">**Exercise:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH8uflRFx85T"
   },
   "source": [
    "\n",
    "**Troubleshooting**\n",
    "\n",
    "Looking at a docs page is helpful for troubleshooting certain errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkXak3U_x85T"
   },
   "source": [
    ">**Exercise:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slrPcyhQx85T"
   },
   "source": [
    "**Exploring**\n",
    "\n",
    "If you are trying to find a specific way to customize the pie chart, it is worth reading the entire list of parameters to see what options are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd92x71jx85U"
   },
   "source": [
    ">**Discussion:** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBhIoXLYA0eH"
   },
   "source": [
    "## Refresher: importing libraries\n",
    "\n",
    "Recall that we covered how to **import libraries** of functions previously. For instance, we can import the built-in `math` library and then use the functions it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbKYBQaEBEfA",
    "outputId": "596338be-b16a-4739-b38e-c8be34562057"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "print(math.log(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2OKWugKBHiz"
   },
   "source": [
    "We need to type `math.` so Python knows where to look for the `log()` function.\n",
    "\n",
    "We can also use an **alias** if we don't want to type `math.` every time we use a function from the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJgUVBvVBRaj",
    "outputId": "7b59e9c7-803f-44f5-bac3-d41745ba03e9"
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "print(m.log(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing data in base python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdI_L_hYx85w"
   },
   "source": [
    "In this next section, we'll read data of bird names and bird sightings from two CSV files and then write out the total number of sightings for each bird to a new CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giOIYpjjx85w"
   },
   "source": [
    "### Reading data line by line\n",
    "\n",
    "A common way to read data in Python is line by line. This is useful when you have a file that is too large to fit into memory all at once. You can read the file line by line and process each line as you go. This is also useful when you need to parse a file that has a specific structure so that it can be read into a data structure like a numpy array or pandas dataframe. In this section, when we talk about files, we mean text files that contain data that exist on your local machine. This is different from the data structures we've been working with so far, which are in memory (in your python instance).\n",
    "\n",
    "The syntax for opening a file is `open(filename, mode)`, where mode can be `r` for reading, `w` for writing, `a` for appending. Reading mode means that you can only read the file but not change it (on the disk). Writing mode means you are creating a new file or overwriting an existing file. Appending mode means you are adding to an existing file.\n",
    "\n",
    "When you open a file, you can read it line by line using a `for` loop. While there are several ways to open a file in Python, the most efficient is with the `with` keyword, which will automatically close the file once you've done what you need. Here's an example of how that might look with a for loop to print each line of a file:\n",
    "\n",
    "```python\n",
    "with open('filename.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        print(line)\n",
    "```\n",
    "\n",
    "The above code will print each line of the file to the console. Notice the use of the keyword `as`, similar to how we setup an **alias** when we import a library. Here it serves a similar purpose, giving us a name to refer to the file object we've opened. We can name it anything we want, but `file` was just an example. The `line` variable is how we refer to each line of the file as we iterate through it. Again, it's an arbitrary name.\n",
    "\n",
    "This for loop is similar to how we iterate through a list. The only difference is that we're iterating through something that is being read from our local computer rather than an object in memory.\n",
    "\n",
    "In the example, we are only printing the lines of the file, but just as with any for loop, you can do anything you want with each line, such as apply a function to it, split it up and store it in a data structure, or write different parts of it to a new file. So think of that `print(line)` line as a placeholder for whatever you want to do with the line.\n",
    "\n",
    "### Vocab\n",
    "\n",
    "|Term|Definition|\n",
    "|---|---|\n",
    "|File|A collection of data stored on a disk|\n",
    "|Line|A string of characters that ends with a newline character|\n",
    "|Newline character|A special character that indicates the end of a line, usually `\\n`|\n",
    "|Delimiter|A character that separates data fields in a line, usually a comma, tab, or space|\n",
    "|Parsing|The process of extracting data from a file|\n",
    "|Whitespace|Any character that represents a space, tab, or newline|\n",
    "|Leading/trailing whitespace|Whitespace at the beginning or end of a string|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGOqaBSNx85w"
   },
   "source": [
    "Let's work through a more concrete example of how we might read and then parse through a file. Let's suppose we have a list of taxon ids and bird names that we want to read into a **dictionary**. The file looks like this:\n",
    "\n",
    "```\n",
    "Anas rubripes,American Black Duck,6924\n",
    "Fulica americana,American Coot,473\n",
    "Spinus tristis,American Goldfinch,145310\n",
    "Falco sparverius,American Kestrel,4665\n",
    "```\n",
    "\n",
    "First, run this block to download the file to the Jupyter notebook environment.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yVz5frKx85w",
    "outputId": "7efa4170-de95-4d79-9e5b-a5dcba13d889"
   },
   "outputs": [],
   "source": [
    "# This line downloads the file locally to the same folder as your notebook\n",
    "!wget https://raw.githubusercontent.com/harvardinformatics/python-intensive/refs/heads/main/data/bird_names.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXTSzHKfEt4H"
   },
   "source": [
    "Then, in the code below we first read the file line by line, then strip the whitespace and split the line by a comma. Then, we will create a dictionary where the key is the taxon id and the value is the common name of the bird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLbmpFrRx85x",
    "outputId": "9061cea8-1787-4d7d-f8f8-427c06d2cf4a"
   },
   "outputs": [],
   "source": [
    "filename = 'bird_names.csv'\n",
    "\n",
    "bird_names = dict()\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().split(',')\n",
    "        # split out line[2]\n",
    "        bird_names[line[2]] = line[1]\n",
    "\n",
    "print(bird_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lagv03K5x85x"
   },
   "source": [
    ">*Discussion:* Explain each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbwh5p-sx85x"
   },
   "source": [
    "Here are some handy functions when working with lines in files. These are all string methods, so you can use them on any string, including strings that are read from a file.\n",
    "\n",
    "**Useful functions for reading files by line**\n",
    "\n",
    "| Function | Description |\n",
    "| --- | --- |\n",
    "| `.strip()` | Removes leading and trailing whitespace and newlines from a string |\n",
    "| `.split()` | Splits a string into a list of strings based on a delimiter |\n",
    "| `.join()` | Joins a list of strings into a single string with a delimiter |\n",
    "| `line[:]` | Indexing and slicing works on strings too |\n",
    "| `.replace(old, new)` | Replaces all instances of `old` with `new` in a string |\n",
    "\n",
    "**Useful special characters**\n",
    "\n",
    "Special characters in files are often used as delimiters or to indicate the end of a line. The two most common special characters are:\n",
    "\n",
    "| Character | Description |\n",
    "| --- | --- |\n",
    "| `\\n` | Newline character |\n",
    "| `\\t` | Tab character |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-YfuiJ-x85x"
   },
   "source": [
    ">**Exercise**: Copy the code above and modify it so that the dictionary keys are the taxon ids and the values are another dictionary, with keys 'scientific_name' and 'common_name' and values the appropriate entries for that bird species.\n",
    ">\n",
    "> For example, a sample dictionary entry should look like this:\n",
    "> ```\n",
    "> {6924: {'scientific_name': 'Anas rubripes', 'common_name': 'American Black Duck'}}\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GQJqgU1x85x",
    "outputId": "674fdca6-7948-45be-c0c0-9da6ec8139d9"
   },
   "outputs": [],
   "source": [
    "filename = 'bird_names.csv'\n",
    "\n",
    "# Your code here\n",
    "bird_names = dict()\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().split(',')\n",
    "        bird_names[line[2]] = {'scientific_name': line[0], 'common_name': line[1]}\n",
    "\n",
    "print(bird_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kMtFgKwx85y"
   },
   "source": [
    ">**Exercise**: Why did we use a dictionary to store the data in the previous exercise? Think about what features of a dictionary make it a good choice or what features of lists or arrays make them a bad choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71hcjRU_x85y"
   },
   "source": [
    "Below is an excerpt from a file of iNaturalist observations of birds in Cambridge, MA from the year 2023. We will loop through the file and count the number of observations of each species. We will also use the previously created dictionary to get the species names.\n",
    "\n",
    "```csv\n",
    "id,time_observed_at,taxon_id\n",
    "145591043,2023-01-01 17:33:31 UTC,14886\n",
    "145610149,2023-01-01 20:55:00 UTC,7004\n",
    "145610383,2023-01-01 21:13:00 UTC,6993\n",
    "145611915,2023-01-01 21:12:00 UTC,13858\n",
    "```\n",
    "\n",
    "Run the code block below to download the file to the Jupyter notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nbIH3wix85y"
   },
   "outputs": [],
   "source": [
    "# This line downloads the file locally to the same folder as your notebook\n",
    "!wget https://raw.githubusercontent.com/harvardinformatics/python-intensive/refs/heads/main/data/bird_observations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuOgnWGbx85y"
   },
   "source": [
    ">**Exercise:** Work with a neighbor or two to do the following exercise:\n",
    "> Loop through the file and count the number of observations of each species. After all the observations have been counted, print all the species names and the number of observations. You will need to use the dictionary you created in the previous exercise to get the species names. It's up to you what kind of data structure (if any) you want to use to store the counts.\n",
    ">\n",
    "> 1. Write out pseudocode for what you will do for each line in your birdfile\n",
    "> 2. Try to turn the pseudocode into python code. If there's something you want to do, but don't know the syntax or function, raise your hand and we can help you.\n",
    "> 3. Find out how many European Starlings were observed as proof that your code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCCEeNG_x85y"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "filename = 'bird_observations.csv' #keep\n",
    "\n",
    "bird_observations = dict()\n",
    "\n",
    "with open(filename, 'r') as birdfile: #keep\n",
    "    # skip the header\n",
    "    next(birdfile) #keep\n",
    "    for line in birdfile: #keep\n",
    "        # clean up the line and split into list\n",
    "        observation = line.strip().split(',')\n",
    "        # get the bird id\n",
    "        id = observation[2]\n",
    "        # get the bird name by looking up in the bird_names dictionary\n",
    "        name = bird_names[id]['common_name']\n",
    "        # if this is the first time we're seeing the bird, add it to our observations dict\n",
    "        if name not in bird_observations:\n",
    "            bird_observations[name] = 0\n",
    "        # increment the count by 1\n",
    "        bird_observations[name] += 1\n",
    "print(bird_observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K_SotU8x85z"
   },
   "source": [
    "If you routinely find yourself reading delimited files, you might want to use the `csv` library. The `csv` library also has the ability to parse Excel files or read and write to/from dictionaries directly. For more information, here's the [doc page](https://docs.python.org/3/library/csv.html). Here's what the above code would look like using the `csv` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEf9BOh6x85z"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'bird_observations.csv'\n",
    "\n",
    "bird_observations = dict()\n",
    "\n",
    "with open(filename, 'r') as birdfile:\n",
    "    # this line takes the place of us having to strip and split the lines\n",
    "    reader = csv.reader(birdfile, delimiter=',')\n",
    "    # skip the header\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        id = row[2]\n",
    "        name = bird_names[id]['common_name']\n",
    "        if name not in bird_observations:\n",
    "            bird_observations[name] = 0\n",
    "        bird_observations[name] += 1\n",
    "print(bird_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URDI7ZBGx85z"
   },
   "source": [
    "### Writing data by line\n",
    "\n",
    "Writing data to a file is similar to reading data from a file. You can open a file in write mode and then write to it line by line using the `print()` method, but this time passing in the variable we've stored the opened file in (in our case the variable is unimaginatively named `file`). Here's an example of writing a list of strings to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvSaq_GVx85z"
   },
   "outputs": [],
   "source": [
    "my_text = ['this is a test', 'this is another test', 'this is the final test']\n",
    "\n",
    "with open('my_text.txt', 'w') as file:\n",
    "    for line in my_text:\n",
    "        print(line, file=file)\n",
    "\n",
    "# reading it back\n",
    "with open('my_text.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq01Vdw2x85z"
   },
   "source": [
    ">**BONUS Exercise:** Use the `csv` module to write the species counts to a new file. The file should have two columns: the species name and the number of observations. The file should be comma-delimited. How this is written may depend on how you stored the species counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkMI3wZ4x850"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('bird_counts.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['bird', 'count'])\n",
    "    for bird, count in bird_observations.items():\n",
    "        writer.writerow([bird, count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "In this section, we will learn about a python package called `pandas` that contains very helpful functions and data structures just for flat data types like the tab or comma-delimited files you might normally read in Excel. In previous iterations of this class, we taught both `pandas` and `numpy`. In this workshop, we will focus on `pandas` only, and do a deeper dive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data to pandas\n",
    "One of the most useful features of pandas DataFrames is its ability to easily perform complex data transformations. This makes it a powerful tool for cleaning, filtering, and summarizing tabular data. As shown above, we can manually create a DataFrame from scratch, but more commonly you will want to read in data from an external source, such as the output of a bioinformatic program, and do some manipulation of it. Let's read some data into a DataFrame to demonstrate. \n",
    "\n",
    "Below you can see an example of how to read files into pandas using the `pd.read_csv()` function. The `csv` stands for 'comma-separated values', which means by defaults it will assume that our columns are separated by **commas**; if we wanted to change the delimiter (e.g. in the case of a tab-separated file), we can set the delimiter explicitly using the `sep=` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-07-28/penguins.csv\", sep=',')\n",
    "\n",
    "# The head() function from pandas prints only the first N lines of a dataframe (default: 10)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When importing data into a DataFrame, pandas automatically detects what data type each column should be. For example, if the column contains only numbers, it will be imported as an floating point or integer data type. If the column contains strings or a mixture of strings and numbers, it will be imported as an \"object\" data type. Below are the different data types for the penguins column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through a dataframe\n",
    "As a note, if we want to go through a dataframe line-by-line (i.e. row by row), because both the rows and columns are indexed it requires slightly more syntax than looping through other data structures (e.g. a dictionary or list). Specifically we need to use the `.iterrows()` method to make the data frame iterable. The `.iterrows()` method outputs each row as a `Series` object with a row index and the column:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in penguins.iterrows():\n",
    "    print(f\"Row index: {index}, {row['species']}, {row['island']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be slow for very large dataframes, but is useful if you need to perform actions on individual rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Consider: based on what we've learned the past several days, what are some *limitations* of `numpy`? Can you think of any tasks you might want to do or analysis you might like to perform that would be difficult with `numpy`? Does this give you a guess as to what `pandas` specializes in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: `numpy` is specialized primarily for numerical operations, e.g. matrix multiplication, vector math, etc., but is more limited when dealing with other data types such as string, python objects, etc. In contrast, `pandas` objects are able to handle mixed data easily! As you will often run into this type of data when doing bioinformatics, `pandas` can be very useful.\n",
    "\n",
    "Before we dive into the syntax, let's take a look at an example real-world application of `pandas` for a task that you might commonly face in biology. We are going to use the \"Palmer penguins\" dataset, which is a collection of various biometric data for several different penguin species and is a commonly used example dataset. Let's take a quick look at what the data looks like.\n",
    "\n",
    "In the Palmer penguins dataset, each row represents an individual penguin, and each column represent a different measurement or characteristic of the penguin, such as its body mass or island of origin. The data are organized in this way so that variables (things we may want to compare against each other) are the columns while observations (the individual penguins) are the rows. This is a common way to organize data in data science and is called **tidy data**. Tidy data formatting also makes it easy to use code to manipulate and analyze, which we will see in this lesson. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-07-28/penguins.csv')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a transformation that we will be able to do with `pandas` that would be difficult to do manually or with `numpy`. We can summarize the data by calculating the average body mass (in kg) of each penguin species, broken up by sex. Using a few lines of code we can go from our raw data to a table that looks like this:\n",
    "\n",
    "\n",
    "| species   | sex    | body_mass_kg|\n",
    "|-----------|--------|----------|\n",
    "| Adelie    | female | 3.368836 |\n",
    "| Adelie    | male   | 4.043493 |\n",
    "| Chinstrap | female | 3.527206 |\n",
    "| Chinstrap | male   | 3.938971 |\n",
    "| Gentoo    | female | 4.679741 |\n",
    "| Gentoo    | male   | 5.484836 |\n",
    "\n",
    "\n",
    "Now, let's get started learning how this is done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pandas Series\n",
    "A `Series` is the simplest data structure in Pandas. They are one dimensional (1D) objects composed of a **single data type** of any variety (string, integers); you can basically think of them as a single column in a spreadsheet. They are similar to arrays in `numpy`, however unlike those other 1D structures Series also have **label-based indexing**, meaning each element in the object can be accessed by specifying its specific label. In that way, they are similar to dictionaries in python. \n",
    "\n",
    "We can manually create a Series in several ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `pd.Series()` function, we provide it the data we want to store as a list, and optionally we can give each row of the data a label using the `index` argument. If we don't give it the index argument, it will automatically assign a numerical index to each row starting from 0. \n",
    "\n",
    "When we print the Series, it will display as a column with the index on the left and the data on the right. The type of data being held in the series will be displayed at the bottom of the output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the pd.Series method:\n",
    "s0 = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "print(s0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the pd.Series method:\n",
    "s1 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "print(s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to create a Series is to convert a (non-nested) dictionary into a Series. The keys of the dictionary will become the index labels while the values will become the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from dictionary to series\n",
    "my_dictionary = {'first': 10, 'second': 20, 'third': 30}\n",
    "s2 = pd.Series(my_dictionary)\n",
    "\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access specific elements in the Series by referring to its index label enclosed in quotes and brackets. This is very similar to how a dictionary works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s0[0])\n",
    "\n",
    "print(s1[\"a\"])\n",
    "\n",
    "print(s2[\"second\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-indexed Series\n",
    "\n",
    "Series objects may have multiple levels of indices. We call this **multi-indexed**. Using layers of indexing is a way of representing two-dimensional data within a one-dimensional `Series` object. Some people really like using multi-indexed Series. You can create a multi-indexed series by passing a list of lists to the `index` argument of the `pd.Series()` function. The first list will be the outermost level of the index, the second list will be the next level, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = [[\"California\", \"California\", \"New York\", \"New York\", \"Texas\", \"Texas\"], \n",
    "            [2001, 2002, 2001, 2002, 2001, 2002]]\n",
    "my_values = [1.5, 1.7, 3.6, 4.2, 3.2, 4.5]\n",
    "\n",
    "s3 = pd.Series(my_values, index=my_index)\n",
    "\n",
    "print(s3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving an item from this data structure is similar to a nested dictionary, using successive `[]` notation. Or, you can passs it a tuple. You must pass the index labels in the order they were created (left to right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3[\"California\"])\n",
    "\n",
    "print(\"---\")\n",
    "print(s3[\"California\"][2001])\n",
    "\n",
    "print(\"---\")\n",
    "print(s3[(\"California\", 2001)])\n",
    "\n",
    "print(\"---\")\n",
    "# you can also use slicing to select multiple elements\n",
    "print(s3[\"California\":\"New York\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our work, we typically don't use multi-indexed Series. However, they are often the output of pandas functions, so it's good to know how to work with them. If you don't like the idea of multi-indexed Series, you can always convert them to a DataFrame using the `reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "While Series is a \"one-dimensional\" data structure, DataFrames are two-dimensional. Where Series can only contain one type of data, the pandas DataFrame can have a combination of numerical and categorical data. Additionally, DataFrames allow you do have labels for your rows and columns. \n",
    "\n",
    "DataFrames are essentially a **collection of Series objects**. You can also think of python DataFrames as spreadsheets from Excel or dataframes from R. \n",
    "\n",
    "Let's manually create a simple dataframe in pandas to showcase their behavior. In the below code, we create a dictionary where the keys are the column names and the values are lists of data. We then pass this dictionary to the `pd.DataFrame()` function to create a DataFrame. \n",
    "\n",
    "When we print the DataFrame, it will display as a table with the column names at the top and the data below. The index (in this case, automatically generated numerical index starting at 0) will be displayed on the left side of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournamentStats = {\n",
    "    \"wrestler\": [\"Terunofuji\", \"Ura\", \"Shodai\", \"Takanosho\"],\n",
    "    \"wins\": [13, 6, 10, 12],\n",
    "    \"rank\": [\"yokozuna\", \"maegashira2\", \"komusubi\", \"maegashira6\"]\n",
    "}\n",
    "\n",
    "#Converting to a pandas DataFrame\n",
    "sumo = pd.DataFrame(tournamentStats)\n",
    "\n",
    "print(sumo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes have many **attributes**, including `shape`, `columns`, `index`, `dtypes`. These are useful for understanding the structure of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumo.shape)\n",
    "\n",
    "print(\"---\")\n",
    "print(sumo.columns)\n",
    "\n",
    "print(\"---\")\n",
    "print(sumo.index)\n",
    "\n",
    "print(\"---\")\n",
    "print(sumo.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames also have the handy `info()` function that summarizes the contents of the dataframe, including counts of the non-null values of each column and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data in a Pandas dataframe\n",
    "\n",
    "As with series objects, pandas dataframes rows and columns are *explicitly indexed*, which means that every row and column has a label associated with it. You can think of the explicit indices as the being the names of the rows and the names of the columns.  \n",
    "\n",
    "Unfortunately, in pandas the syntax for subsetting rows v.s. columns is different and can get a little confusing, so let's go through several different use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns\n",
    "We can always check the names of the columns in a Pandas dataframe byt using the built-in `.columns` method, which simply lists the column index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to refer to a specific column, we can specify its index (enclosed in double quotes) inside of square brackets `[]` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single column:\n",
    "sumo[\"wrestler\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to refer to *multiple* columns, we need to pass the columns as a **list** by enclosing the column indices in square brackets, so you will end up with *double brackets*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple columns (note the double []!):\n",
    "sumo[[\"wrestler\", \"rank\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows:\n",
    "\n",
    "The syntax for selecting specific rows is slightly different. Let's first check the labels of the row index; to do this we use the `.index` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumo.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that while the column index labels were strings, the row index labels are *numerical values*, in this case `0` thru `3`. If we wanted to pull out the first row, we need to specify its index label (`0`) in combination with the `.loc` method (which is required for rows): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to select multiple rows, like with columns we need to pass it as a list using the double brackets. If we want to specify a **range** of rows (i.e. from this row to that row), we **don't** use double brackets and instead use `:`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumo.loc[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sumo.loc[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the row index labels are numbers, but do not have to be numerical, and can have string labels similar to columns. Let's show how we could change the row index labels by taking the column with the wrestler's rank and setting it as the index label (note that the labels should be unique!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo = sumo.set_index(\"rank\")\n",
    "\n",
    "print(sumo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo.loc[\"yokozuna\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to use `.loc` if we are referring to a specific row AND column, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumo.loc[\"komusubi\", \"wrestler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to purely use numerical indexing, we can use the `.iloc()` method. If you use `.iloc()`, you can index a DataFrame just as you would a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows and the first two columns\n",
    "\n",
    "sumo.iloc[0:2, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to select subsets of a dataframe. The rows and columns of a dataframe can be referred to either by their integer position or by their indexed name. Typically, for columns, you'll use the indexed name and can just do `[]` with the name of the column. For rows, if you want to use the integer position, you will use `.iloc[]`. If you want to use the index name, you will use `.loc[]`. \n",
    "\n",
    "For reference, here's a handy table on the best ways to index into a dataframe:\n",
    "\n",
    "|Action|Named index|Integer Position|\n",
    "|---|---|---|\n",
    "|Select single column|`df['column_name']`|`df.iloc[:, column_position]`|\n",
    "|Select multiple columns|`df[['column_name1', 'column_name2']]`|`df.iloc[:, [column_position1, column_position2]]`|\n",
    "|Select single row|`df.loc['row_name']`|`df.iloc[row_position]`|\n",
    "|Select multiple rows|`df.loc[['row_name1', 'row_name2']]`|`df.iloc[[row_position1, row_position2]]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exercise: we'll use the penguins dataset from our initial example.\n",
    "> 1) Print the 'species' column\n",
    "> 2) Print the first five columns and first five rows\n",
    "> 3) Print the columns \"species\", \"island\", and \"sex\" and the first ten rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "print(penguins['species'])\n",
    "\n",
    "print(\"---\")\n",
    "print(penguins.iloc[0:5,0:5])\n",
    "\n",
    "print(\"---\")\n",
    "print(penguins.loc[0:10, ['species', 'island', 'sex']])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pyworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
